# ETL-Spotify | Data Engineering Project

![Arquitectura](etl-arquitectura.png)

## DescripciÃ³n del Proyecto

Repositorio para el proyecto final del curso Data Engineering en [CODERHOUSE](https://www.coderhouse.com/).

En este proyecto, llevaremos a cabo un proceso ETL (Extract, Transform, Load) utilizando datos extraÃ­dos de la WEB API de [Spotify](https://developer.spotify.com/documentation/web-api/tutorials/getting-started). A continuaciÃ³n, transforma los datos y los carga en AWS Redshift. Todo el proceso estarÃ¡ automatizado mediante el uso de Apache Airflow.

El objetivo principal es extraer informaciÃ³n del catÃ¡logo de Spotify sobre el top 10 de las mejores canciones de un artista por paÃ­s.

## Tabla de Contenidos

-   [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
-   [Requisitos](#requisitos)
-   [InstalaciÃ³n](#instalaciÃ³n)
-   [Estructura del Proyecto](#estructura-del-proyecto)
-   [Licencia](#licencia)

## Requisitos

[Enumera aquÃ­ todos los requisitos necesarios para ejecutar y utilizar tu proyecto. Pueden incluir software especÃ­fico, bibliotecas, versiones de Python, etc. Proporciona instrucciones claras para que los usuarios puedan preparar su entorno correctamente.]

1. Registrarse en la API de [Spotify](https://developer.spotify.com/documentation/web-api/tutorials/getting-started) siguiendo los pasos que te proporciona. Con esto obtendremos los siguientes datos:
    - CLIENT_ID
    - CLIENT_SECRECT
2. Tener instalado [Docker](https://www.docker.com/) en tu laptop.
3. Tener una cuenta en AWS o reemplazar las conexiones por una DB en localhost, por ejemplo, PostgreSQL.

## InstalaciÃ³n

1. Crear las siguientes carpetas a la misma altura del `docker-compose.yml`.
```bash
mkdir logs
mkdir plugins
mkdir postgres_data
```
2. Crear un archivo con variables de entorno llamado `.env` ubicado a la misma altura que el `docker-compose.yml`. Cuyo contenido sea:
```bash
REDSHIFT_HOST=... # YOUR_REDSHIFT_HOST
REDSHIFT_PORT=... # YOUR_REDSHIFT_PORT
REDSHIFT_DB=... # YOUR_REDSHIFT_DB
REDSHIFT_USER=... # YOUR_REDSHIFT_USER
REDSHIFT_SCHEMA=... # YOUR_REDSHIFT_SCHEMA
REDSHIFT_PASSWORD=... # YOUR_REDSHIFT_PASSWORD
REDSHIFT_URL="jdbc:postgresql://${REDSHIFT_HOST}:${REDSHIFT_PORT}/${REDSHIFT_DB}?user=${REDSHIFT_USER}&password=${REDSHIFT_PASSWORD}"
DRIVER_PATH=/tmp/drivers/postgresql-42.5.2.jar
SPOTIFY_CLIENT_ID="YOUR_CLIENT_ID"
SPOTIFY_CLIENT_SECRET="YOUR_CLIENT_SECRET"
```
3. Descargar las imagenes de Airflow y Spark. En caso de error al descargar las imagenes, debe hacer un login en DockerHub.
```bash
docker pull lucastrubiano/airflow:airflow_2_6_2
docker pull lucastrubiano/spark:spark_3_4_1
```
4. Las imagenes fueron generadas a partir de los Dockerfiles ubicados en `docker_images/`. Si se desea generar las imagenes nuevamente, ejecutar los comandos que estÃ¡n en los Dockerfiles.
5. Ejecutar el siguiente comando para levantar los servicios de Airflow y Spark.
```bash
docker-compose up --build
```
6. Una vez que los servicios estÃ©n levantados, ingresar a Airflow en `http://localhost:8080/`.
7. En la pestaÃ±a `Admin -> Connections` crear una nueva conexiÃ³n con los siguientes datos para Redshift:
    * Conn Id: `redshift_default`
    * Conn Type: `Amazon Redshift`
    * Host: `host de redshift`
    * Database: `base de datos de redshift`
    * Schema: `esquema de redshift`
    * User: `usuario de redshift`
    * Password: `contraseÃ±a de redshift`
    * Port: `5439`
8. En la pestaÃ±a `Admin -> Connections` crear una nueva conexiÃ³n con los siguientes datos para Spark:
    * Conn Id: `spark_default`
    * Conn Type: `Spark`
    * Host: `spark://spark`
    * Port: `7077`
    * Extra: `{"queue": "default"}`
9. En la pestaÃ±a `Admin -> Variables` crear una nueva variable con los siguientes datos:
    * Key: `driver_class_path`
    * Value: `/tmp/drivers/postgresql-42.5.2.jar`
10. En la pestaÃ±a `Admin -> Variables` crear una nueva variable con los siguientes datos:
    * Key: `spark_scripts_dir`
    * Value: `/opt/airflow/scripts`
11. En la pestaÃ±a `Admin -> Variables` crear las nuevas variables con los siguientes datos:
    * Key: `SMTP_EMAIL_FROM`
    * Value: `your_email_from@example.com`
    * Key: `SMTP_EMAIL_PASSWORD`
    * Value: `your_smtp_password`
    * Key: `SMTP_EMAIL_TO`
    * Value: `your_email_to@example.com`
12. Ejecutar el DAG `etl_spotify`.

## Estructura del Proyecto

    ğŸ“dags
        etl_spotify.py
    ğŸ“docker_images
        ğŸ“airflow
            Dockerfile
            requirements.txt
        ğŸ“spark
            Dockerfile
    ğŸ“plugins
    ğŸ“logs
    ğŸ“postgres_data
    ğŸ“scripts
        commons.py
        ETL_Spotify.py
        helpers.py
    .gitignore
    .env
    docker-compose.yml
    README.md

### Tabla: popular_songs

Esta tabla almacena informaciÃ³n sobre canciones populares. A continuaciÃ³n se muestra la descripciÃ³n de sus columnas:

| Columna | Tipo de dato | DescripciÃ³n |  
|  -------------- | ------------ | ---------------------------------------|  
| id_song |  VARCHAR(250)  | Identificador Ãºnico de la canciÃ³n. |  
| song_name |  VARCHAR(250) | TÃ­tulo de la canciÃ³n. |  
| artist |  VARCHAR(250) | Nombre del artista o banda. |
| album  |  VARCHAR(150) | Nombre del Ã¡lbum. |
| popularity | INTEGER | Popularidad de la canciÃ³n. |
| duration_ms | INTEGER  | DuraciÃ³n de la canciÃ³n en milisegundos. |
| song_link  | VARCHAR(250)  | Link de la canciÃ³n. |
| country_code  | VARCHAR(2)  | CÃ³digo del paÃ­s donde se escucha la canciÃ³n. |
| timestamp_  | TIMESTAMP  | Marca de tiempo en que se ejecuta el etl. |
| alternate_key  | VARCHAR(255) | Identificador alternativo usado como PRIMARY KEY |


## Licencia
Este proyecto se encuentra bajo la [Licencia MIT](LICENSE.txt)
    

## Contacto
Hola ğŸ‘‹ Â¿CÃ³mo estÃ¡s? Si te gustÃ³ este proyecto y quieres saber mÃ¡s, puedes contactarme por algunas de estas redes ğŸ™‚

âœ‰ lautaropoletto@gmail.com

ğŸ‘¨â€ğŸ’» https://github.com/lpoletto

ğŸ™‹â€â™‚ï¸ https://www.linkedin.com/in/lautaro-poletto/ 


## CrÃ©ditos

Algunos de los recursos utilizados en el proyecto fueron creados por el Profesor Lucas Trubiano. ğŸ‘‰ https://github.com/lucastrubiano